{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d614a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T08:12:10.358995Z",
     "start_time": "2024-04-11T08:12:10.343990Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617786d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T08:12:18.551419Z",
     "start_time": "2024-04-11T08:12:12.060297Z"
    }
   },
   "source": [
    "# Define the directory where your data files are located\n",
    "data_dir = os.path.join('..')\n",
    "\n",
    "# Construct file paths using os.path.join()\n",
    "file_facts = os.path.join(data_dir, 'PostNL_account_delivery_facts_anonymized.csv')\n",
    "file_preference = os.path.join(data_dir, 'PostNL_account_delivery_preference_anonymized.csv')\n",
    "file_packages = os.path.join(data_dir, 'PostNL_collo_packages_anonymized.csv')\n",
    "\n",
    "# Read data into data framesgit \n",
    "df_facts = pd.read_csv(file_facts)\n",
    "df_preference = pd.read_csv(file_preference)\n",
    "df_packages = pd.read_csv(file_packages)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fc40ad2c",
   "metadata": {},
   "source": [
    "# PostNL account delivery facts\n",
    "* The analysis shows that there are no nans or abnormal variables present in the data. \n",
    "* The total number of parcels varies month to month, with some months showing higher variability.\n",
    "* There's a difference between the number of parcels delivered and those successfully delivered to the home on the first try.\n",
    "* Certain months may have anomalies or outliers in the number of parcels delivered which could be due to various factors (seasonal demand, promotions, shipping delays, etc.).\n",
    "* The scatter plot with jitter effectively shows the distribution and density of the data points for each month, which the violin plot abstracts into a density shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dd0bcf",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:12:27.825390Z",
     "start_time": "2024-04-11T08:12:27.806380Z"
    }
   },
   "source": [
    "df_facts.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffa3122",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:27.085544Z",
     "start_time": "2024-04-02T20:23:27.070551Z"
    }
   },
   "source": [
    "df_facts.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae888f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:27.196547Z",
     "start_time": "2024-04-02T20:23:27.087513Z"
    }
   },
   "source": [
    "df_facts.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc8752f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:31.351594Z",
     "start_time": "2024-04-02T20:23:27.197514Z"
    }
   },
   "source": [
    "sns.boxplot(data=df_facts[['number_of_parcels', 'parcels_home_1st']])\n",
    "plt.title('Boxplot of number_of_parcels and parcels_home_1st')\n",
    "plt.xlabel('Parcel type')\n",
    "plt.ylabel('Amount of parcels')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Makes a visualisation of the number of parcels delivered each month \n",
    "df_facts_grouped_date = df_facts[['month_id', 'number_of_parcels', 'parcels_home_1st']].copy() #remove hased id \n",
    "df_facts_grouped_date = df_facts_grouped_date.groupby('month_id').sum()\n",
    "df_facts_grouped_date.reset_index(inplace=True)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_facts_grouped_date['month_id'], df_facts_grouped_date['number_of_parcels'],\n",
    "         marker='o', label='Number of Parcels')\n",
    "plt.plot(df_facts_grouped_date['month_id'], df_facts_grouped_date['parcels_home_1st'],\n",
    "         marker='o', label='Parcels Home 1st')\n",
    "plt.title('Number of Parcels and Parcels Home 1st Over Time')\n",
    "plt.xlabel('Month ID')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:31.654628Z",
     "start_time": "2024-04-02T20:23:31.352594Z"
    }
   },
   "id": "d70bcc48",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#subset of data only containing the month id and the number of parcels\n",
    "df_month_parcels = df_facts[['month_id', 'number_of_parcels']]\n",
    "\n",
    "# Convert month_id to a more readable format, \"YYYY-MM\", to make the plot more understandable\n",
    "df_month_parcels['month_id'] = pd.to_datetime(df_month_parcels['month_id'], format='%Y%m').dt.strftime('%Y-%m')\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(15, 6))  # Adjust the figure size as necessary\n",
    "sns.violinplot(x='month_id', y='number_of_parcels', data=df_month_parcels)\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
    "plt.title('Number of Parcels per Month')  # You can customize the title\n",
    "plt.xlabel('Month')  # X-axis label\n",
    "plt.ylabel('Number of Parcels')  # Y-axis label\n",
    "plt.tight_layout()  # Adjust the layout to make sure everything fits without overlapping\n",
    "plt.show()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:40.405718Z",
     "start_time": "2024-04-02T20:23:31.655592Z"
    }
   },
   "id": "da8b7e0e",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.stripplot(x='month_id', y='number_of_parcels', data=df_month_parcels, jitter=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Scatter Plot with Jitter for Number of Parcels per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Parcels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.725765Z",
     "start_time": "2024-04-02T20:23:40.406717Z"
    }
   },
   "id": "6ea08fd6",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Post NL preferences\n",
    "* The type of the columns that contain a date are objects however date time might be more suitable for analysis.\n",
    "* This data **cannot** provide you information whether a customer changed their delivery preference since there are no duplicate accounts present. \n",
    "* Most accounts have OriginalDeliveryLocation as their preference, which I assume is their house.\n",
    "* There are some NaN delivery preferences which should be changed to NULL values in the DB.\n",
    "* I assume that all rows for which \"datelastupdated\" =! Nan the account has changed their delivery preference, but it should be validated. \n",
    "* Around 70% of the accounts does not have information about when the delivery preference was updated and created, therefore I assume that 70% of the users have not changed their delivery preference.\n",
    "* Most packages are delivered on Tuesdays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edf6c49aca1f3fd9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d9baf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.741352Z",
     "start_time": "2024-04-02T20:23:42.726766Z"
    }
   },
   "source": [
    "df_preference.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0fbf52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.757318Z",
     "start_time": "2024-04-02T20:23:42.744320Z"
    }
   },
   "source": [
    "#Check type\n",
    "df_preference.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d81ef72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.916321Z",
     "start_time": "2024-04-02T20:23:42.758359Z"
    }
   },
   "source": [
    "# Convert date columns from object to datetime\n",
    "df_preference['datelastupdated'] = pd.to_datetime(df_preference['datelastupdated'])\n",
    "df_preference['datecreated'] = pd.to_datetime(df_preference['datecreated'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f485c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.932322Z",
     "start_time": "2024-04-02T20:23:42.918324Z"
    }
   },
   "source": [
    "#Check type\n",
    "df_preference.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd98edfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.948321Z",
     "start_time": "2024-04-02T20:23:42.933320Z"
    }
   },
   "source": [
    "#prints unique delivery preferences in the data\n",
    "print(df_preference['deliverypreference'].unique())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10e47cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:42.995317Z",
     "start_time": "2024-04-02T20:23:42.949321Z"
    }
   },
   "source": [
    "#Check for double account_id\n",
    "duplicate_count = df_preference['account_id_hashed'].duplicated().sum()\n",
    "print(\"Amount of duplicate account ids: {}\".format(duplicate_count))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc982657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.043323Z",
     "start_time": "2024-04-02T20:23:42.996322Z"
    }
   },
   "source": [
    "#Amount of accounts for which there is no delivery preference known \n",
    "nan_count = df_preference['deliverypreference'].isna().sum()\n",
    "print(\"Amount of accounts for which there is no delivery preference known:\", nan_count)\n",
    "\n",
    "#Change the NaN value to Unknown\n",
    "df_preference['deliverypreference'] = df_preference['deliverypreference'].fillna('Unknown')\n",
    "df_preference"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f1664b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.297395Z",
     "start_time": "2024-04-02T20:23:43.045324Z"
    }
   },
   "source": [
    "# Count the occurrence of each delivery preference\n",
    "preference_counts = df_preference['deliverypreference'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "preference_counts.plot(kind='bar')\n",
    "plt.xlabel('Delivery Preference')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Delivery Preference Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c89195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.313395Z",
     "start_time": "2024-04-02T20:23:43.298396Z"
    }
   },
   "source": [
    "nan_count = df_preference['datecreated'].isna().sum() #counts nans\n",
    "not_nan = len(df_preference) - nan_count #counts not nans\n",
    "percent = round(((not_nan/nan_count)*100), 1) #calculates percentage that is not nan\n",
    "\n",
    "print(\"Amount of accounts for which there is no date created:\", nan_count)\n",
    "print(\"So amount of account for which there is a date created:\", not_nan)\n",
    "print(\"Therefore {}% of the accounts have a date created\".format(percent))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0971d3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.329395Z",
     "start_time": "2024-04-02T20:23:43.314395Z"
    }
   },
   "source": [
    "nan_count = df_preference['datelastupdated'].isna().sum() #counts nans\n",
    "not_nan = len(df_preference) - nan_count #counts not nans\n",
    "percent = round(((not_nan/nan_count)*100), 1) #calculates percentage that is not nan\n",
    "\n",
    "print(\"Amount of accounts for which there is no date updated:\", nan_count)\n",
    "print(\"So amount of account for which there is a date date updated:\", not_nan)\n",
    "print(\"Therefore {}% of the accounts have a date updated\".format(percent))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1192229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.360361Z",
     "start_time": "2024-04-02T20:23:43.330366Z"
    }
   },
   "source": [
    "df_packages.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccadc92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.376404Z",
     "start_time": "2024-04-02T20:23:43.362365Z"
    }
   },
   "source": [
    "df_packages.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70fb8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:23:43.392396Z",
     "start_time": "2024-04-02T20:23:43.379398Z"
    }
   },
   "source": [
    "df_packages.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61bd2136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:09.036641Z",
     "start_time": "2024-04-02T20:23:43.394382Z"
    }
   },
   "source": [
    "#Change all columns that contain an date or time to a datetime format for further analysis \n",
    "date_time_columns_list = list(df_packages.columns)[2:14]\n",
    "\n",
    "for column in date_time_columns_list:\n",
    "    # Using errors='coerce' to convert out-of-bounds or unparseable dates to NaT\n",
    "    df_packages[column] = pd.to_datetime(df_packages[column], errors='coerce')\n",
    "    \n",
    "    if 'tijd' in column.lower(): \n",
    "        df_packages[column] = df_packages[column].dt.time\n",
    "\n",
    "df_packages"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcda49ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:11.624587Z",
     "start_time": "2024-04-02T20:25:09.037574Z"
    }
   },
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = df_packages[df_packages.duplicated()]\n",
    "duplicate_rows"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ee3c9b",
   "metadata": {},
   "source": [
    "**Account ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "838cc912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:11.672657Z",
     "start_time": "2024-04-02T20:25:11.626599Z"
    }
   },
   "source": [
    "#Checks how many packages are linked to an account\n",
    "packages_without_account = df_packages['account_id_hashed'].isna().sum()\n",
    "percentage_not_linked = round(((packages_without_account/len(df_packages))*100), 1)\n",
    "\n",
    "print(\"The total amont of packages which are not linked to a specific acount:\", packages_without_account)\n",
    "print(\"Precentage of packages not linked to an account: {}%\".format(percentage_not_linked))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dbfe6a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:12.288656Z",
     "start_time": "2024-04-02T20:25:11.673664Z"
    }
   },
   "source": [
    "# Remove rows where 'account_id_hashed' is NaN\n",
    "df_cleaned = df_packages.dropna(subset=['account_id_hashed'])\n",
    "\n",
    "# Now, find duplicates in the cleaned DataFrame\n",
    "duplicated_mask = df_cleaned['account_id_hashed'].duplicated(keep=False)\n",
    "duplicated_account_ids = df_cleaned[duplicated_mask]\n",
    "duplicated_account_ids"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0956fb16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:12.794693Z",
     "start_time": "2024-04-02T20:25:12.290623Z"
    }
   },
   "source": [
    "# Check id which has ordered the most packages according to df_packages\n",
    "most_frequent_account_id_hashed = df_packages['account_id_hashed'].value_counts().idxmax()\n",
    "print(most_frequent_account_id_hashed)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cd54b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:12.889700Z",
     "start_time": "2024-04-02T20:25:12.795673Z"
    }
   },
   "source": [
    "df_packages[df_packages['account_id_hashed'] == '696d0cff331b6b26d8672faa9285fdda7bbb7d616ca122ed6880020e00311313']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "44110f43",
   "metadata": {},
   "source": [
    "**Barcodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca10db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:13.097701Z",
     "start_time": "2024-04-02T20:25:12.895706Z"
    }
   },
   "source": [
    "#Check amount of duplicate barcodes\n",
    "duplicate_barcodes = df_packages[df_packages.duplicated('dn_barcode', keep=False)]['dn_barcode'].unique()\n",
    "print(\"Amount of duplicate barcodes:\", len(duplicate_barcodes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3e6f611e",
   "metadata": {},
   "source": [
    "**Landcode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73010941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:13.145670Z",
     "start_time": "2024-04-02T20:25:13.099713Z"
    }
   },
   "source": [
    "#Are there any packages delived else then NL\n",
    "df_packages['da_landcode_gea'].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a7efb024",
   "metadata": {},
   "source": [
    "**Eindstatus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "780d78f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:13.192670Z",
     "start_time": "2024-04-02T20:25:13.146671Z"
    }
   },
   "source": [
    "df_eindstatus = df_packages[[\"account_id_hashed\", \"da_datum_eindstatus\", \"da_tijd_eindstatus\"]]\n",
    "df_eindstatus"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89ab6b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:16.702077Z",
     "start_time": "2024-04-02T20:25:13.194674Z"
    }
   },
   "source": [
    "# Convert 'da_datum_eindstatus' to datetime to extract the day of the week\n",
    "df_packages['da_datum_eindstatus'] = pd.to_datetime(df_packages['da_datum_eindstatus'])\n",
    "df_packages['weekday'] = df_packages['da_datum_eindstatus'].dt.day_name()\n",
    "\n",
    "# Convert 'da_tijd_eindstatus' to a categorical time slot (consider hourly slots)\n",
    "df_packages['hour'] = pd.to_datetime(df_packages['da_tijd_eindstatus'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Aggregate data to count occurrences per weekday and hour\n",
    "heatmap_data = df_packages.groupby(['hour', 'weekday']).size().unstack(fill_value=0)\n",
    "\n",
    "# Sort the data by days of the week in correct order\n",
    "sorter = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "# Ensure the columns are in the correct weekday order\n",
    "heatmap_data = heatmap_data[sorter]\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\", annot=False, cbar_kws={'label': 'Frequency'})\n",
    "plt.title('Frequency of Status End Times by Day of Week and Hour')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Hour of the Day')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "681d2cdc",
   "metadata": {},
   "source": [
    "**Waarnemings sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analysis shows that waarnemings sequence cannot be derived from the columns in the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e07f4195c560cd"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f334046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:16.971221Z",
     "start_time": "2024-04-02T20:25:16.703109Z"
    }
   },
   "source": [
    "df_waarneming = df_packages[['da_waarnemingsequence']].copy()\n",
    "df_waarneming['amount'] = 1\n",
    "df_waarneming_grouped = df_waarneming.groupby('da_waarnemingsequence').sum()\n",
    "df_waarneming_grouped.reset_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23c4ca68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:16.987221Z",
     "start_time": "2024-04-02T20:25:16.972213Z"
    }
   },
   "source": [
    "df_waarneming_grouped['amount'].describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1752fa91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:17.018267Z",
     "start_time": "2024-04-02T20:25:16.989218Z"
    }
   },
   "source": [
    "# Sort the DataFrame by the column containing the values\n",
    "sorted_df = df_waarneming_grouped.sort_values(by='amount', ascending=False)\n",
    "\n",
    "# Keep only the top 10 values\n",
    "top_10 = sorted_df.head(10)\n",
    "top_10"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "983cd0bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:17.240268Z",
     "start_time": "2024-04-02T20:25:17.020274Z"
    }
   },
   "source": [
    "def find_similarities(df, da_waarnemingsequence_values=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Identifies columns with identical values within groups of a DataFrame, grouped by 'da_waarnemingsequence'.\n",
    "    It filters by specific values if provided, then returns a dictionary of these similarities for each group.\n",
    "    Goal of doing this is checking whether rows with the same 'da_waarnemingsequence' have any other column values in common.git\n",
    "    \"\"\"\n",
    "        \n",
    "    # If specific values are provided, filter the DataFrame to include only those groups\n",
    "    if da_waarnemingsequence_values is not None:\n",
    "        if isinstance(da_waarnemingsequence_values, list):\n",
    "            df = df[df['da_waarnemingsequence'].isin(da_waarnemingsequence_values)]\n",
    "        else:\n",
    "            df = df[df['da_waarnemingsequence'] == da_waarnemingsequence_values]\n",
    "    \n",
    "    # Grouping the DataFrame by 'da_waarnemingsequence'\n",
    "    grouped = df.groupby('da_waarnemingsequence')\n",
    "    results = {}\n",
    "\n",
    "    for name, group in grouped:\n",
    "        # Dictionary to hold similarities for the current group\n",
    "        similarities = {}\n",
    "        for column in group.columns:\n",
    "            # Skip the grouping column\n",
    "            if column == 'da_waarnemingsequence':\n",
    "                continue\n",
    "            # Check if all values in the column are the same\n",
    "            if group[column].nunique() == 1:\n",
    "                # Add to similarities\n",
    "                similarities[column] = group[column].iloc[0]\n",
    "        # Add the similarities for the current group to the results\n",
    "        if similarities:\n",
    "            results[name] = similarities\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage for a specific value of 'da_waarnemingsequence'\n",
    "similarities = find_similarities(df_packages, 'A98A01A95B01A96J01J40A19A19J05I01')\n",
    "print(similarities)\n",
    "\n",
    "# Example usage for multiple specific values of 'da_waarnemingsequence'\n",
    "# similarities = find_similarities(df_packages, ['value1', 'value2'])\n",
    "# print(similarities)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee20a84",
   "metadata": {},
   "source": [
    "# Delivery facts & collo packages"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I analyse whether the person that received the most packages in the delivery facts also appears as many times in the collo packages because this should be consistent.\n",
    "\n",
    "Analysis shows that it is not consistent, further validation why is needed. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d373967ee9c1353"
  },
  {
   "cell_type": "code",
   "source": [
    "#check if the range of the dates are comparable \n",
    "\n",
    "# Finding the earliest date\n",
    "min_date_packages = df_packages['da_datum_eindstatus'].min()\n",
    "min_date_facts = df_facts['month_id'].min()\n",
    "\n",
    "# Finding the latest date\n",
    "max_date_packages = df_packages['da_datum_eindstatus'].max()\n",
    "max_date_facts = df_facts['month_id'].max()\n",
    "\n",
    "print(f\"The date range from df_packages is from {min_date_packages} to {max_date_packages}\")\n",
    "print(f\"The date range from df_facts is from {min_date_facts} to {max_date_facts}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:17.272272Z",
     "start_time": "2024-04-02T20:25:17.242274Z"
    }
   },
   "id": "c24c2e8f318fd53",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Check who received the most packages according to the delivery facts \n",
    "\n",
    "#groups account by id \n",
    "df_total_parcels_per_id = df_facts[['account_id_hashed', 'number_of_parcels']].copy().groupby('account_id_hashed').sum()\n",
    "\n",
    "# Sort the DataFrame by the column containing the values\n",
    "sorted_df = df_total_parcels_per_id.sort_values(by='number_of_parcels', ascending=False)\n",
    "sorted_df = sorted_df.reset_index()\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:18.320303Z",
     "start_time": "2024-04-02T20:25:17.274278Z"
    }
   },
   "id": "70e423465577b454",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check the months in which the customer received packages\n",
    "account_most_packages = sorted_df['account_id_hashed'].iloc[0]\n",
    "df_facts[df_facts['account_id_hashed'] == account_most_packages]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:18.400284Z",
     "start_time": "2024-04-02T20:25:18.322272Z"
    }
   },
   "id": "3af028cee26263c4",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Check if this customer also appears as many times in the collo packages\n",
    "df_packages[df_packages['account_id_hashed'] == account_most_packages]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T20:25:18.478286Z",
     "start_time": "2024-04-02T20:25:18.402286Z"
    }
   },
   "id": "307d573c9067c9b2",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Possibility for data enrichment \n",
    "We could add additional data to prove that the model can perform with newly added data, in this case 4 digit postal code information in the Netherlands.\n",
    "Github repo: https://github.com/bobdenotter/4pp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8de1d5abc2e43ceb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
